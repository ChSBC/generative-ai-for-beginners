# Основи інженерії промптів 

[![Основи інженерії промптів](./images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Вступ
Цей модуль охоплює основні концепції та техніки створення ефективних промптів у моделях генеративного ШІ. Спосіб написання вашого промпту до LLM також має значення. Ретельно складений промпт може досягти кращої якості відповіді. Але що саме означають такі терміни як _промпт_ та _інженерія промптів_? І як мені покращити _вхідний_ промпт, який я надсилаю до LLM? Це ті питання, на які ми спробуємо відповісти в цьому та наступному розділах.

_Генеративний ШІ_ здатний створювати новий контент (наприклад, текст, зображення, аудіо, код тощо) у відповідь на запити користувачів. Він досягає цього за допомогою _Великих мовних моделей_, таких як серія GPT ("Generative Pre-trained Transformer") від OpenAI, які навчені використовувати природну мову та код.

Користувачі тепер можуть взаємодіяти з цими моделями за допомогою знайомих парадигм, як чат, без необхідності в технічній експертизі чи навчанні. Моделі базуються на _промптах_ - користувачі надсилають текстовий вхід (промпт) і отримують відповідь ШІ (завершення). Потім вони можуть "спілкуватися з ШІ" ітеративно, у багатоходових розмовах, уточнюючи свій промпт, доки відповідь не відповідатиме їхнім очікуванням.

"Промпти" тепер стають основним _програмним інтерфейсом_ для додатків генеративного ШІ, вказуючи моделям, що робити та впливаючи на якість поверених відповідей. "Інженерія промптів" - це швидкозростаюча галузь досліджень, яка фокусується на _проектуванні та оптимізації_ промптів для забезпечення постійних та якісних відповідей у масштабі.

## Цілі навчання

У цьому уроці ми дізнаємося, що таке інженерія промптів, чому вона важлива, і як ми можемо створювати більш ефективні промпти для конкретної моделі та цілі додатку. Ми зрозуміємо основні концепції та найкращі практики інженерії промптів - і дізнаємося про інтерактивне середовище Jupyter Notebooks "пісочниця", де ми можемо побачити ці концепції застосованими до реальних прикладів.

Після завершення цього уроку ми зможемо:

1. Пояснити, що таке інженерія промптів і чому вона важлива.
2. Описати компоненти промпту та як вони використовуються.
3. Вивчити найкращі практики та техніки інженерії промптів.
4. Застосувати вивчені техніки до реальних прикладів, використовуючи кінцеву точку OpenAI.

## Ключові терміни

Інженерія промптів: Практика проектування та уточнення входів для спрямування моделей ШІ на створення бажаних виходів.
Токенізація: Процес перетворення тексту на менші одиниці, які називаються токенами, які модель може зрозуміти та обробити.
LLM, налаштовані на інструкції: Великі Мовні Моделі (LLM), які були точно налаштовані з конкретними інструкціями для покращення точності та релевантності відповідей.

## Навчальна пісочниця

Інженерія промптів наразі більше мистецтво, ніж наука. Найкращий спосіб покращити нашу інтуїцію для неї - це _більше практикуватися_ і прийняти підхід проб і помилок, який поєднує експертизу в предметній області з рекомендованими техніками та оптимізаціями, специфічними для моделі.

Jupyter Notebook, що супроводжує цей урок, надає _пісочницю_ - середовище, де ви можете спробувати те, що вивчаєте - у процесі або як частину кодового завдання в кінці. Для виконання вправ вам знадобиться:

1. **Ключ API Azure OpenAI** - кінцева точка сервісу для розгорнутої LLM.
2. **Середовище виконання Python** - в якому може виконуватись Notebook.
3. **Локальні змінні середовища** - _виконайте кроки [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) зараз, щоб підготуватися_.

Notebook містить _початкові_ вправи - але ви заохочуєтесь додавати свої власні секції _Markdown_ (опис) та _Code_ (запити промптів), щоб спробувати більше прикладів або ідей - і розвивати свою інтуїцію щодо проектування промптів.

## Ілюстрований посібник

Хочете отримати загальне уявлення про те, що охоплює цей урок, перш ніж занурюватися? Перегляньте цей ілюстрований посібник, який дає вам розуміння основних тем та ключових моментів для роздумів у кожній з них. Дорожня карта уроку веде вас від розуміння основних концепцій та викликів до їх вирішення за допомогою відповідних технік інженерії промптів та найкращих практик. Зверніть увагу, що розділ "Розширені техніки" в цьому посібнику стосується контенту, який охоплюється в _наступному_ розділі цього навчального плану.

![Ілюстрований посібник з інженерії промптів](./images/04-prompt-engineering-sketchnote.png?WT.mc_id=academic-105485-koreyst)

## Наш стартап 

Тепер поговорімо про те, як _ця тема_ пов'язана з місією нашого стартапу [привнести інновації ШІ в освіту](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Ми хочемо створити додатки на основі ШІ для _персоналізованого навчання_ - тож давайте подумаємо про те, як різні користувачі нашого додатку можуть "проектувати" промпти:

- **Адміністратори** можуть попросити ШІ _проаналізувати дані навчального плану, щоб виявити прогалини в охопленні_. ШІ може підсумувати результати або візуалізувати їх за допомогою коду.
- **Викладачі** можуть попросити ШІ _створити план уроку для цільової аудиторії та теми_. ШІ може створити персоналізований план у визначеному форматі.
- **Студенти** можуть попросити ШІ _допомогти їм у складному предметі_. ШІ тепер може направляти студентів за допомогою уроків, підказок та прикладів, адаптованих до їхнього рівня.

Це лише верхівка айсберга. Перегляньте [Промпти для освіти](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - бібліотеку промптів з відкритим кодом, підібрану експертами в галузі освіти - щоб отримати ширше уявлення про можливості! _Спробуйте запустити деякі з цих промптів у пісочниці або використовуючи OpenAI Playground, щоб побачити, що станеться!_

## Що таке інженерія промптів?

Ми почали цей урок з визначення **Інженерії промптів** як процесу _проектування та оптимізації_ текстових входів (промптів) для забезпечення послідовних та якісних відповідей (завершень) для заданої цілі додатку та моделі. Ми можемо розглядати це як 2-етапний процес:

- _проектування_ початкового промпту для заданої моделі та цілі
- _уточнення_ промпту ітеративно для покращення якості відповіді

Це обов'язково є процесом проб і помилок, який вимагає інтуїції та зусиль користувача для отримання оптимальних результатів. То чому це важливо? Щоб відповісти на це питання, нам спочатку потрібно зрозуміти три концепції:

- _Токенізація_ = як модель "бачить" промпт
- _Базові LLM_ = як фундаментальна модель "обробляє" промпт
- _LLM, налаштовані на інструкції_ = як модель тепер може бачити "завдання"

### Токенізація

LLM бачить промпти як _послідовність токенів_, де різні моделі (або версії моделі) можуть токенізувати один і той же промпт по-різному. Оскільки LLM навчаються на токенах (а не на сирому тексті), спосіб токенізації промптів має прямий вплив на якість згенерованої відповіді.

Щоб отримати інтуїтивне розуміння того, як працює токенізація, спробуйте такі інструменти, як [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), показаний нижче. Скопіюйте свій промпт - і подивіться, як він перетворюється в токени, звертаючи увагу на те, як обробляються пробіли та знаки пунктуації. Зауважте, що цей приклад показує старішу LLM (GPT-3) - тому спроба цього з новішою моделлю може дати інший результат.

![Tokenization](./images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### Концепт: Фундаментальні моделі

Після токенізації промпту, основна функція ["Базової LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (або Фундаментальної моделі) полягає в передбаченні токена в цій послідовності. Оскільки LLM навчені на масивних наборах текстових даних, вони мають хороше розуміння статистичних зв'язків між токенами і можуть робити це передбачення з певною впевненістю. Зауважте, що вони не розуміють _значення_ слів у промпті чи токені; вони просто бачать шаблон, який можуть "завершити" своїм наступним передбаченням. Вони можуть продовжувати передбачати послідовність доки не будуть зупинені втручанням користувача або якоюсь заздалегідь встановленою умовою.

Хочете побачити, як працює завершення на основі промптів? Введіть наведений вище промпт у [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) Azure OpenAI Studio з налаштуваннями за замовчуванням. Система налаштована на обробку промптів як запитів на інформацію - тому ви повинні побачити завершення, яке відповідає цьому контексту.

Але що, якщо користувач хотів побачити щось конкретне, що відповідало б певним критеріям чи цілям завдання? Ось тут на сцену виходять LLM, _налаштовані на інструкції_.

![Instruction Tuned LLM Chat Completion](./images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## Чому нам потрібна інженерія промптів?

Тепер, коли ми знаємо, як промпти обробляються LLM, давайте поговоримо про те, _чому_ нам потрібна інженерія промптів. Відповідь полягає в тому, що сучасні LLM створюють ряд викликів, які роблять досягнення _надійних і послідовних завершень_ більш складним без докладання зусиль до конструювання та оптимізації промптів. Наприклад:

1. **Відповіді моделей є стохастичними.** _Один і той же промпт_ імовірно буде створювати різні відповіді з різними моделями або версіями моделей. І він може навіть давати різні результати з _тією ж моделлю_ в різний час. _Техніки інженерії промптів можуть допомогти нам мінімізувати ці варіації, забезпечуючи кращі обмеження_.

1. **Моделі можуть фабрикувати відповіді.** Моделі попередньо навчені на _великих, але кінцевих_ наборах даних, що означає, що їм бракує знань про концепції поза межами цього навчального обсягу. В результаті вони можуть створювати завершення, які є неточними, уявними або прямо суперечать відомим фактам. _Техніки інженерії промптів допомагають користувачам ідентифікувати та зменшувати такі фабрикації, наприклад, запитуючи в ШІ цитати або обґрунтування_.

1. **Можливості моделей будуть відрізнятися.** Новіші моделі або покоління моделей матимуть багатші можливості, але також принесуть унікальні особливості та компроміси в вартості й складності. _Інженерія промптів може допомогти нам розробити найкращі практики та робочі процеси, які абстрагують відмінності та адаптуються до специфічних вимог моделей масштабованими, безшовними способами_.

Давайте подивимось це в дії в OpenAI або Azure OpenAI Playground:

- Використайте той самий промпт з різними розгортаннями LLM (наприклад, OpenAI, Azure OpenAI, Hugging Face) - чи побачили ви варіації?
- Використайте той самий промпт повторно з _тим самим_ розгортанням LLM (наприклад, Azure OpenAI playground) - як відрізнялися ці варіації?

### Приклад фабрикацій

У цьому курсі ми використовуємо термін **"фабрикація"** для позначення явища, коли LLM іноді генерують фактично неправильну інформацію через обмеження в їхньому навчанні чи інші обмеження. Ви також могли чути це як _"галюцинації"_ в популярних статтях чи дослідницьких роботах. Однак, ми наполегливо рекомендуємо використовувати термін _"фабрикація"_, щоб ми випадково не антропоморфізували поведінку, приписуючи людиноподібну рису результату, керованому машиною. Це також підкріплює [принципи Відповідального ШІ](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) з термінологічної точки зору, видаляючи терміни, які також можуть вважатися образливими або неінклюзивними в деяких контекстах.

Хочете отримати уявлення про те, як працюють фабрикації? Подумайте про промпт, який дає вказівку ШІ генерувати контент для неіснуючої теми (щоб переконатися, що її немає в навчальному наборі даних). Наприклад - я спробував цей промпт:

> **Промпт:** створіть план уроку про Марсіанську війну 2076 року.

Пошук в інтернеті показав мені, що були вигадані історії (наприклад, телесеріали або книги) про марсіанські війни - але жодної в 2076 році. Здоровий глузд також підказує нам, що 2076 рік _у майбутньому_, і, отже, не може бути пов'язаний з реальною подією.

То що ж відбувається, коли ми запускаємо цей промпт з різними провайдерами LLM?

> **Відповідь 1**: OpenAI Playground (GPT-35)

![Відповідь 1](./images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)

> **Відповідь 2**: Azure OpenAI Playground (GPT-35)

![Відповідь 2](./images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Відповідь 3**: Hugging Face Chat Playground (LLama-2)

![Відповідь 3](./images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

Як і очікувалося, кожна модель (або версія моделі) створює дещо різні відповіді завдяки стохастичній поведінці та варіаціям можливостей моделі. Наприклад, одна модель орієнтується на аудиторію 8-го класу, тоді як інша передбачає старшокласника. Але всі три моделі згенерували відповіді, які могли б переконати непоінформованого користувача, що подія була реальною.

Техніки інженерії промптів, такі як _метапромптинг_ та _конфігурація температури_, можуть деякою мірою зменшити фабрикації моделей. Нові _архітектури_ інженерії промптів також безшовно включають нові інструменти та техніки в потік промптів для пом'якшення або зменшення деяких з цих ефектів.

## Практичний приклад: GitHub Copilot

Давайте завершимо цей розділ, отримавши уявлення про те, як інженерія промптів використовується в реальних рішеннях, розглянувши один практичний приклад: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot - це ваш "ШІ-напарник програміст" - він перетворює текстові промпти в завершення коду та інтегрований у ваше середовище розробки (наприклад, Visual Studio Code) для безперебійного користувацького досвіду. Як задокументовано в серії блогів нижче, найраніша версія базувалася на моделі OpenAI Codex - інженери швидко усвідомили необхідність точного налаштування моделі та розробки кращих технік інженерії промптів для покращення якості коду. У липні вони [представили вдосконалену модель ШІ, що виходить за межі Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) для ще швидших пропозицій.

Прочитайте пости по порядку, щоб прослідкувати їхній шлях навчання.

- **Травень 2023** | [GitHub Copilot стає кращим у розумінні вашого коду](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Травень 2023** | [Всередині GitHub: Робота з LLM за GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Червень 2023** | [Як писати кращі промпти для GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Липень 2023** | [.. GitHub Copilot виходить за межі Codex з вдосконаленою моделлю ШІ](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Липень 2023** | [Посібник розробника з інженерії промптів та LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Вересень 2023** | [Як створити корпоративний додаток LLM: Уроки від GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Ви також можете переглянути їхній [Інженерний блог](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) для більшої кількості постів, як [цей](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), який показує, як ці моделі та техніки _застосовуються_ для створення реальних додатків.

## Конструювання промптів

Ми побачили, чому інженерія промптів важлива - тепер давайте зрозуміємо, як промпти _конструюються_, щоб ми могли оцінити різні техніки для більш ефективного проектування промптів.

### Базовий промпт

Почнемо з базового промпту: текстового вводу, надісланого моделі без будь-якого іншого контексту. Ось приклад - коли ми надсилаємо перші кілька слів національного гімну США до [API завершення](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) OpenAI, він миттєво _завершує_ відповідь наступними рядками, ілюструючи базову поведінку передбачення.

| Промпт (Ввід)     | Завершення (Вивід)                                                                                                                      |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Схоже, ви починаєте текст "The Star-Spangled Banner," національного гімну Сполучених Штатів. Повний текст такий... |

### Складний промпт

Тепер давайте додамо контекст та інструкції до цього базового промпту. [API завершення чату](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) дозволяє нам конструювати складний промпт як колекцію _повідомлень_ з:

- Парами ввід/вивід, що відображають ввід _користувача_ та відповідь _асистента_.
- Системним повідомленням, що встановлює контекст для поведінки або особистості асистента.

Запит тепер має форму, наведену нижче, де _токенізація_ ефективно захоплює релевантну інформацію з контексту та розмови. Тепер зміна системного контексту може мати такий же вплив на якість завершень, як і надані користувачем вводи.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Промпт з інструкціями

У наведених вище прикладах промпт користувача був простим текстовим запитом, який можна інтерпретувати як запит на інформацію. З промптами _з інструкціями_ ми можемо використовувати цей текст для більш детального визначення завдання, надаючи краще керівництво для ШІ. Ось приклад:

| Промпт (Ввід)                                                                                                                                                                                                                          | Завершення (Вивід)                                                                                                         | Тип інструкції     |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Напишіть опис Громадянської війни                                                                                                                                                                                                    | _повернув простий параграф_                                                                                               | Простий             |
| Напишіть опис Громадянської війни. Надайте ключові дати та події та опишіть їх значення                                                                                                                                      | _повернув параграф, за яким слідує список ключових дат подій з описами_                                              | Складний            |
| Напишіть опис Громадянської війни в 1 параграфі. Надайте 3 пункти з ключовими датами та їх значенням. Надайте ще 3 пункти з ключовими історичними фігурами та їх внесками. Поверніть результат як JSON файл  | _повертає більш розширені деталі в текстовому полі, відформатовані як JSON, який ви можете скопіювати-вставити у файл та перевірити за потреби_ | Складний. Форматований. |

## Основний контент

У наведених вище прикладах промпт все ще був досить відкритим, дозволяючи LLM вирішувати, яка частина її попередньо навченого набору даних була релевантною. З шаблоном проектування _основного контенту_ вхідний текст розділяється на дві частини:

- інструкція (дія)
- релевантний контент (який впливає на дію)

Ось приклад, де інструкція - "підсумуйте це у 2 реченнях".

| Промпт (Ввід)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Завершення (Вивід)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Юпітер - п'ята планета від Сонця і найбільша в Сонячній системі. Це газовий гігант з масою в одну тисячну від маси Сонця, але в два з половиною рази більшою за масу всіх інших планет Сонячної системи разом узятих. Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком у нічному небі, і був відомий древнім цивілізаціям ще до писаної історії. Він названий на честь римського бога Юпітера.[19] При спостереженні з Землі Юпітер може бути достатньо яскравим, щоб його відбите світло створювало видимі тіні,[20] і в середньому є третім за яскравістю природним об'єктом у нічному небі після Місяця та Венери. <br/> **Підсумуйте це у 2 коротких реченнях** | Юпітер, п'ята планета від Сонця, є найбільшою в Сонячній системі і відома як один з найяскравіших об'єктів у нічному небі. Названий на честь римського бога Юпітера, це газовий гігант, маса якого в два з половиною рази більша за масу всіх інших планет Сонячної системи разом узятих. |

Сегмент основного контенту можна використовувати різними способами для створення більш ефективних інструкцій:

- **Приклади** - замість того, щоб явно вказувати моделі, що робити, надайте їй приклади того, що робити, і дозвольте їй вивести шаблон.
- **Підказки** - слідуйте за інструкцією "підказкою", яка готує завершення, спрямовуючи модель до більш релевантних відповідей.
- **Шаблони** - це повторювані 'рецепти' для промптів із заповнювачами (змінними), які можна налаштувати даними для конкретних випадків використання.

Давайте розглянемо це в дії.

### Використання прикладів

Це підхід, де ви використовуєте основний контент, щоб "підгодувати модель" деякими прикладами бажаного виводу для заданої інструкції, і дозволити їй вивести шаблон для бажаного виводу. Базуючись на кількості наданих прикладів, ми можемо мати промптинг з нуля (zero-shot), з одним прикладом (one-shot), з кількома прикладами (few-shot) тощо.

Промпт тепер складається з трьох компонентів:

- Опис завдання
- Кілька прикладів бажаного виводу 
- Початок нового прикладу (який стає неявним описом завдання)

| Тип навчання | Промпт (Ввід)                                                                                                                                           | Завершення (Вивід)          |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot     | "The Sun is Shining". Перекласти іспанською                                                                                                            | "El Sol está brillando".    |
| One-shot      | "The Sun is Shining" => "El Sol está brillando". <br> "It's a Cold and Windy Day" =>                                                                    | "Es un día frío y ventoso". |
| Few-shot      | Гравець пробіг по базах => Бейсбол <br/> Гравець зробив ейс => Теніс <br/> Гравець вдарив шістку => Крикет <br/> Гравець зробив слем-данк =>         | Баскетбол                   |
|               |                                                                                                                                                         |                             |

Зверніть увагу, як нам довелося надати явну інструкцію ("Перекласти іспанською") у промптингу з нуля, але вона виводиться у прикладі промптингу з одним прикладом. Приклад з кількома прикладами показує, як додавання більшої кількості прикладів дозволяє моделям робити точніші висновки без додаткових інструкцій.

### Підказки промпту

Інша техніка використання основного контенту полягає в наданні _підказок_ замість прикладів. У цьому випадку ми даємо моделі поштовх у правильному напрямку, _починаючи_ із фрагмента, який відображає бажаний формат відповіді. Модель потім "бере підказку" для продовження в цьому напрямку.

| Кількість підказок | Промпт (Ввід)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Завершення (Вивід)                                                                                                                                                                                                                                                                                       |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                  | Юпітер - п'ята планета від Сонця і найбільша в Сонячній системі. Це газовий гігант з масою в одну тисячну від маси Сонця, але в два з половиною рази більшою за масу всіх інших планет Сонячної системи разом узятих. Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком у нічному небі, і був відомий древнім цивілізаціям ще до писаної історії. <br/>**Підсумуйте це**                                       | Юпітер - найбільша планета в нашій Сонячній системі і п'ята від Сонця. Це газовий гігант з масою 1/1000 від маси Сонця, але він важчий за всі інші планети разом узяті. Древні цивілізації знали про Юпітер протягом довгого часу, і його легко побачити в нічному небі. |
| 1                  | Юпітер - п'ята планета від Сонця і найбільша в Сонячній системі. Це газовий гігант з масою в одну тисячну від маси Сонця, але в два з половиною рази більшою за масу всіх інших планет Сонячної системи разом узятих. Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком у нічному небі, і був відомий древнім цивілізаціям ще до писаної історії. <br/>**Підсумуйте це** <br/> Те, що ми дізналися про Юпітер | це п'ята планета від Сонця і найбільша в Сонячній системі. Це газовий гігант з масою в одну тисячну від маси Сонця, але в два з половиною рази більшою за масу всіх інших планет разом узятих. Його легко побачити неозброєним оком, і він був відомий з давніх часів.                        |
| 2                  | Юпітер - п'ята планета від Сонця і найбільша в Сонячній системі. Це газовий гігант з масою в одну тисячну від маси Сонця, але в два з половиною рази більшою за масу всіх інших планет Сонячної системи разом узятих. Юпітер - один з найяскравіших об'єктів, видимих неозброєним оком у нічному небі, і був відомий древнім цивілізаціям ще до писаної історії. <br/>**Підсумуйте це** <br/> Топ 3 фактів, які ми дізналися:         | 1. Юпітер - п'ята планета від Сонця і найбільша в Сонячній системі. <br/> 2. Це газовий гігант з масою в одну тисячну від маси Сонця...<br/> 3. Юпітер видно неозброєним оком з давніх часів ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Шаблони промптів

Шаблон промпту - це _попередньо визначений рецепт для промпту_, який можна зберігати та повторно використовувати за потреби для забезпечення більш послідовного користувацького досвіду в масштабі. У своїй найпростішій формі це просто колекція прикладів промптів, як [цей від OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), який надає як компоненти інтерактивного промпту (повідомлення користувача та системи), так і формат запиту через API - для підтримки повторного використання.

У більш складній формі, як [цей приклад від LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), він містить _заповнювачі_, які можна замінити даними з різних джерел (ввід користувача, системний контекст, зовнішні джерела даних тощо) для динамічного генерування промпту. Це дозволяє нам створити бібліотеку повторно використовуваних промптів, які можна використовувати для забезпечення послідовного користувацького досвіду **програмно** в масштабі.

Нарешті, справжня цінність шаблонів полягає в можливості створювати та публікувати _бібліотеки промптів_ для вертикальних прикладних доменів - де шаблон промпту тепер _оптимізований_ для відображення специфічного для додатку контексту або прикладів, які роблять відповіді більш релевантними та точними для цільової аудиторії користувачів. Репозиторій [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) є чудовим прикладом такого підходу, курируючи бібліотеку промптів для освітньої галузі з акцентом на ключових цілях, таких як планування уроків, розробка навчальних програм, репетиторство студентів тощо.

## Допоміжний контент

Якщо ми думаємо про конструювання промпту як про наявність інструкції (завдання) та цілі (основний контент), тоді _вторинний контент_ - це як додатковий контекст, який ми надаємо, щоб **певним чином вплинути на вивід**. Це можуть бути параметри налаштування, інструкції з форматування, таксономії тем тощо, які можуть допомогти моделі _адаптувати_ свою відповідь відповідно до бажаних цілей або очікувань користувача.

Наприклад: Маючи каталог курсів з розширеними метаданими (назва, опис, рівень, теги метаданих, викладач тощо) про всі доступні курси в навчальній програмі:

- ми можемо визначити інструкцію "підсумувати каталог курсів на осінь 2023 року"
- ми можемо використати основний контент для надання кількох прикладів бажаного виводу
- ми можемо використати вторинний контент для визначення топ-5 "тегів", що цікавлять.

Тепер модель може надати підсумок у форматі, показаному кількома прикладами - але якщо результат має кілька тегів, вона може приоритезувати 5 тегів, визначених у вторинному контенті.

## Найкращі практики промптингу

Тепер, коли ми знаємо, як промпти можуть бути _сконструйовані_, ми можемо почати думати про те, як їх _проектувати_ для відображення найкращих практик. Ми можемо розглядати це в двох частинах - маючи правильний _мисленнєвий підхід_ та застосовуючи правильні _техніки_.

### Мисленнєвий підхід до інженерії промптів

Інженерія промптів - це процес проб і помилок, тому пам'ятайте про три широкі керівні фактори:

1. **Розуміння домену має значення.** Точність і релевантність відповіді є функцією _домену_, в якому працює додаток чи користувач. Застосовуйте свою інтуїцію та експертизу домену для подальшої **настройки технік**. Наприклад, визначте _специфічні для домену особистості_ у ваших системних промптах, або використовуйте _специфічні для домену шаблони_ у ваших користувацьких промптах. Надавайте вторинний контент, який відображає специфічні для домену контексти, або використовуйте _специфічні для домену підказки та приклади_ для спрямування моделі до знайомих шаблонів використання.

2. **Розуміння моделі має значення.** Ми знаємо, що моделі за своєю природою стохастичні. Але реалізації моделей також можуть відрізнятися з точки зору навчального набору даних, який вони використовують (попередньо навчені знання), можливостей, які вони надають (наприклад, через API чи SDK), та типу контенту, для якого вони оптимізовані (наприклад, код проти зображень проти тексту). Зрозумійте сильні та слабкі сторони моделі, яку ви використовуєте, і використовуйте ці знання для _пріоритезації завдань_ або створення _настроюваних шаблонів_, оптимізованих під можливості моделі.

3. **Ітерація та валідація мають значення.** Моделі швидко розвиваються, як і техніки інженерії промптів. Як експерт домену, у вас можуть бути інший контекст чи критерії для _вашого_ конкретного додатку, які можуть не застосовуватися до ширшої спільноти. Використовуйте інструменти та техніки інженерії промптів для "швидкого старту" конструювання промптів, потім ітеруйте та валідуйте результати, використовуючи власну інтуїцію та експертизу домену. Записуйте свої висновки та створюйте **базу знань** (наприклад, бібліотеки промптів), яку інші можуть використовувати як нову базову лінію для швидших ітерацій у майбутньому.

## Найкращі практики

Тепер розглянемо загальні найкращі практики, які рекомендують практики [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) та [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Що                                    | Чому                                                                                                                                                                                                                                               |
| :----------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Оцінюйте найновіші моделі            | Нові покоління моделей, ймовірно, матимуть покращені функції та якість - але також можуть спричинити вищі витрати. Оцініть їх вплив, потім приймайте рішення щодо міграції.                                                                    |
| Розділяйте інструкції та контекст    | Перевірте, чи ваша модель/провайдер визначає _розділювачі_ для чіткішого розрізнення інструкцій, первинного та вторинного контенту. Це може допомогти моделям точніше призначати ваги токенам.                                                 |
| Будьте конкретними та чіткими        | Надавайте більше деталей про бажаний контекст, результат, довжину, формат, стиль тощо. Це покращить як якість, так і послідовність відповідей. Фіксуйте рецепти в шаблонах для повторного використання.                                        |
| Будьте описовими, використовуйте приклади | Моделі можуть краще реагувати на підхід "покажи і розкажи". Почніть з підходу `zero-shot`, де ви даєте інструкцію (але без прикладів), потім спробуйте `few-shot` як уточнення, надаючи кілька прикладів бажаного виводу. Використовуйте аналогії. |
| Використовуйте підказки для швидкого старту | Підштовхніть до бажаного результату, надавши деякі провідні слова чи фрази, які можна використати як відправну точку для відповіді.                                                                                                              |
| Подвоюйте зусилля                    | Іноді вам може знадобитися повторити себе для моделі. Давайте інструкції до і після основного контенту, використовуйте інструкцію та підказку тощо. Ітеруйте та перевіряйте, що працює.                                                         |
| Порядок має значення                  | Порядок, у якому ви представляєте інформацію моделі, може вплинути на вивід, навіть у навчальних прикладах, завдяки упередженню недавності. Спробуйте різні варіанти, щоб побачити, що працює найкраще.                                        |
| Дайте моделі "вихід"                 | Дайте моделі _резервну_ відповідь завершення, яку вона може надати, якщо не може виконати завдання з будь-якої причини. Це може зменшити шанси генерування моделями хибних або сфабрикованих відповідей.                                       |

Як і з будь-якою найкращою практикою, пам'ятайте, що _ваші результати можуть відрізнятися_ залежно від моделі, завдання та домену. Використовуйте їх як відправну точку та ітеруйте, щоб знайти те, що працює найкраще для вас. Постійно переоцінюйте ваш процес інженерії промптів, коли стають доступними нові моделі та інструменти, зосереджуючись на масштабованості процесу та якості відповідей.

## Завдання

Вітаємо! Ви дійшли до кінця уроку! Час перевірити деякі з цих концепцій та технік на реальних прикладах!

Для нашого завдання ми будемо використовувати Jupyter Notebook з вправами, які ви можете виконати інтерактивно. Ви також можете розширити Notebook власними комірками Markdown та Code для дослідження ідей та технік самостійно.

### Для початку зробіть форк репозиторію, потім

- (Рекомендовано) Запустіть GitHub Codespaces
- (Альтернативно) Клонуйте репозиторій на свій локальний пристрій та використовуйте його з Docker Desktop
- (Альтернативно) Відкрийте Notebook у вашому улюбленому середовищі виконання Notebook.

### Далі налаштуйте змінні середовища

- Скопіюйте файл `.env.copy` в кореневій директорії репозиторію в `.env` та заповніть значення `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` та `AZURE_OPENAI_DEPLOYMENT`. Поверніться до розділу [Learning Sandbox](./04-prompt-engineering-fundamentals#learning-sandbox), щоб дізнатися як.

### Потім відкрийте Jupyter Notebook

- Виберіть ядро виконання. Якщо використовуєте варіанти 1 або 2, просто виберіть ядро Python 3.10.x за замовчуванням, що надається dev container.

Ви готові запускати вправи. Зауважте, що тут немає _правильних і неправильних_ відповідей - просто досліджуємо варіанти методом проб і помилок та розвиваємо інтуїцію щодо того, що працює для конкретної моделі та домену додатку.

_З цієї причини в цьому уроці немає сегментів з рішеннями коду. Натомість Notebook матиме комірки Markdown з назвою "Моє рішення:", що показує один приклад виводу для довідки._

## Перевірка знань

Який з наступних промптів є хорошим, дотримуючись розумних найкращих практик?

1. Покажи мені зображення червоного авто
2. Покажи мені зображення червоного авто марки Volvo моделі XC90, припаркованого біля скелі на заході сонця
3. Покажи мені зображення червоного авто марки Volvo моделі XC90

В: 2, це найкращий промпт, оскільки він надає деталі про "що" і вдається в подробиці (не просто будь-яке авто, а конкретної марки та моделі), а також описує загальну обстановку. 3 є наступним найкращим, оскільки він також містить багато опису.

## 🚀 Завдання

Подивіться, чи можете ви використати техніку "підказки" з промптом: Завершіть речення "Покажи мені зображення червоного авто марки Volvo та ". Що воно відповідає, і як би ви це покращили?

## Чудова робота! Продовжуйте навчання

Хочете дізнатися більше про різні концепції інженерії промптів? Перейдіть на [сторінку продовження навчання](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), щоб знайти інші чудові ресурси на цю тему.

Переходьте до Уроку 5, де ми розглянемо [розширені техніки промптингу](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!