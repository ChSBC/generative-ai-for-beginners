{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9bdc79",
   "metadata": {},
   "source": [
    "# Розділ 7: Створення чат-додатків\n",
    "## Швидкий старт з API моделей Github\n",
    "\n",
    "Цей ноутбук адаптовано з [репозиторію прикладів Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), який включає ноутбуки для доступу до сервісів [Azure OpenAI](notebook-azure-openai.ipynb).\n",
    "\n",
    "# Огляд  \n",
    "\"Великі мовні моделі - це функції, які перетворюють текст на текст. Отримавши вхідний рядок тексту, велика мовна модель намагається передбачити текст, який ітиме далі\"(1). Цей \"швидкий старт\" познайомить користувачів з концепціями LLM високого рівня, основними вимогами пакетів для початку роботи з AML, м'яким введенням у дизайн промптів та кількома короткими прикладами різних випадків використання.\n",
    "\n",
    "## Зміст  \n",
    "\n",
    "[Огляд](#огляд)  \n",
    "[Як використовувати сервіс OpenAI](#як-використовувати-сервіс-openai)  \n",
    "[1. Створення вашого сервісу OpenAI](#1.-створення-вашого-сервісу-openai)  \n",
    "[2. Встановлення](#2.-встановлення)    \n",
    "[3. Облікові дані](#3.-облікові-дані)  \n",
    "\n",
    "[Випадки використання](#випадки-використання)    \n",
    "[1. Підсумовування тексту](#1.-підсумовування-тексту)  \n",
    "[2. Класифікація тексту](#2.-класифікація-тексту)  \n",
    "[3. Генерація нових назв продуктів](#3.-генерація-нових-назв-продуктів)  \n",
    "[4. Тонке налаштування класифікатора](#4.тонке-налаштування-класифікатора)  \n",
    "\n",
    "[Посилання](#посилання)\n",
    "\n",
    "### Побудуйте свій перший промпт  \n",
    "Ця коротка вправа надасть базове введення для подання промптів моделі в Github Models для простого завдання \"підсумовування\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b08adb",
   "metadata": {},
   "source": [
    "**Кроки**:  \n",
    "1. Встановіть бібліотеку `azure-ai-inference` у своєму середовищі Python, якщо ви ще цього не зробили.  \n",
    "2. Завантажте стандартні допоміжні бібліотеки та налаштуйте облікові дані для Github Models.  \n",
    "3. Виберіть модель для вашого завдання  \n",
    "4. Створіть простий промпт для моделі  \n",
    "5. Надішліть запит до API моделі!\n",
    "\n",
    "### 1. Встановіть `azure-ai-inference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8c3c9",
   "metadata": {},
   "source": [
    "### 2. Імпортуйте допоміжні бібліотеки та створіть облікові дані"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d395919",
   "metadata": {},
   "source": [
    "### 3. Пошук правильної моделі  \n",
    "Моделі GPT-3.5-turbo або GPT-4 можуть розуміти та генерувати природну мову."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Виберіть модель загального призначення curie для тексту\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6667269",
   "metadata": {},
   "source": [
    "## 4. Дизайн промпту  \n",
    "\n",
    "\"Магія великих мовних моделей полягає в тому, що, навчаючись мінімізувати цю похибку передбачення на великих обсягах тексту, моделі в результаті вивчають концепції, корисні для цих передбачень. Наприклад, вони вивчають такі концепції як\"(1):\n",
    "\n",
    "* як правильно писати\n",
    "* як працює граматика\n",
    "* як перефразовувати\n",
    "* як відповідати на запитання\n",
    "* як вести розмову\n",
    "* як писати багатьма мовами\n",
    "* як кодувати\n",
    "* тощо.\n",
    "\n",
    "#### Як керувати великою мовною моделлю  \n",
    "\"З усіх входів до великої мовної моделі, безумовно, найбільш впливовим є текстовий промпт\"(1).\n",
    "\n",
    "Великі мовні моделі можна спонукати до створення виводу кількома способами:\n",
    "\n",
    "Інструкція: Скажіть моделі, що ви хочете\n",
    "Завершення: Спонукайте модель завершити початок того, що ви хочете\n",
    "Демонстрація: Покажіть моделі, що ви хочете, за допомогою:\n",
    "Кількох прикладів у промпті\n",
    "Багатьох сотень або тисяч прикладів у навчальному наборі даних для тонкого налаштування\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39140d1",
   "metadata": {},
   "source": [
    "#### Існують три основні рекомендації щодо створення промптів:\n",
    "\n",
    "**Показуйте та розповідайте**. Чітко вказуйте, що ви хочете, через інструкції, приклади або їх комбінацію. Якщо ви хочете, щоб модель розташувала список елементів в алфавітному порядку або класифікувала абзац за настроєм, покажіть їй, що саме ви хочете.\n",
    "\n",
    "**Надавайте якісні дані**. Якщо ви намагаєтеся створити класифікатор або змусити модель слідувати певній схемі, переконайтеся, що є достатньо прикладів. Обов'язково перевірте свої приклади — модель зазвичай достатньо розумна, щоб зрозуміти основні орфографічні помилки та дати вам відповідь, але вона також може припустити, що це навмисно, і це може вплинути на відповідь.\n",
    "\n",
    "**Перевіряйте налаштування**. Параметри temperature та top_p контролюють, наскільки детермінованою є модель при генерації відповіді. Якщо ви просите відповідь, де є лише одна правильна відповідь, то вам варто встановити їх нижче. Якщо ви шукаєте більш різноманітні відповіді, то можливо вам захочеться встановити їх вище. Найпоширенішою помилкою, яку люди роблять з цими налаштуваннями, є припущення, що вони є елементами керування \"розумністю\" або \"креативністю\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180b2ef",
   "metadata": {},
   "source": [
    "Джерело: https://github.com/Azure/OpenAI/blob/main/How%20to/Completions.md\n",
    "\n",
    "### 5. Надсилаємо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Створіть свій перший промпт\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f578e8",
   "metadata": {},
   "source": [
    "### Повторіть той самий виклик, як порівнюються результати?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ac150",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466da6ba",
   "metadata": {},
   "source": [
    "## Підсумовування тексту  \n",
    "#### Завдання  \n",
    "Підсумуйте текст, додавши 'tl;dr:' в кінці текстового уривку. Зверніть увагу, як модель розуміє, як виконувати низку завдань без додаткових інструкцій. Ви можете експериментувати з більш описовими промптами, ніж tl;dr, щоб модифікувати поведінку моделі та налаштувати підсумок, який ви отримуєте(3).  \n",
    "\n",
    "Останні роботи продемонстрували значні успіхи в багатьох завданнях та тестах NLP шляхом попереднього навчання на великому корпусі тексту з подальшим тонким налаштуванням на конкретне завдання. Хоча зазвичай архітектура не залежить від завдання, цей метод все ще вимагає наборів даних для тонкого налаштування, специфічних для завдання, які містять тисячі або десятки тисяч прикладів. На відміну від цього, люди зазвичай можуть виконувати нове мовне завдання лише з кількох прикладів або з простих інструкцій - щось, з чим поточні системи NLP все ще значною мірою борються. Тут ми показуємо, що масштабування мовних моделей значно покращує ефективність, не залежну від завдання, з кількома прикладами, іноді навіть досягаючи конкурентоспроможності з попередніми найсучаснішими підходами тонкого налаштування.\n",
    "\n",
    "Tl;dr\n",
    "\n",
    "# Вправи для кількох випадків використання  \n",
    "1. Підсумовування тексту  \n",
    "2. Класифікація тексту  \n",
    "3. Генерація нових назв продуктів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d83b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Встановлення кількох додаткових типових параметрів під час виклику API\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b2da1",
   "metadata": {},
   "source": [
    "## Класифікація тексту  \n",
    "#### Завдання  \n",
    "Класифікуйте елементи на категорії, надані під час виведення. У наступному прикладі ми надаємо як категорії, так і текст для класифікації у промпті(*playground_reference). \n",
    "\n",
    "Запит клієнта: Привіт, одна з клавіш на клавіатурі мого ноутбука нещодавно зламалася, і мені потрібна заміна:\n",
    "\n",
    "Класифікована категорія:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a823a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Встановлення кількох додаткових типових параметрів під час виклику API\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb1048",
   "metadata": {},
   "source": [
    "## Генерація нових назв продуктів\n",
    "#### Завдання\n",
    "Створіть назви продуктів з прикладів слів. Тут ми включаємо в промпт інформацію про продукт, для якого ми збираємося генерувати назви. Ми також надаємо схожий приклад, щоб показати схему, яку ми хочемо отримати. Ми також встановили високе значення температури, щоб збільшити випадковість та отримати більш інноваційні відповіді.\n",
    "\n",
    "Опис продукту: Домашній міксер для молочних коктейлів\n",
    "Ключові слова: швидкий, здоровий, компактний.\n",
    "Назви продуктів: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Опис продукту: Пара взуття, яка може підходити для будь-якого розміру стопи.\n",
    "Ключові слова: адаптивний, що підходить, omni-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d8343",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Встановлення кількох додаткових типових параметрів під час виклику API\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d334f2aa",
   "metadata": {},
   "source": [
    "# Посилання  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Best practices for fine-tuning GPT-3 to classify text](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "# Для отримання додаткової допомоги  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com) \n",
    "\n",
    "# Учасники\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
