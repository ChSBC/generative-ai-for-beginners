{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Розширення генерації на основі пошуку (RAG) та векторні бази даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install getenv openai==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Створення нашої бази знань\n",
    "\n",
    "Створення бази даних Azure Cosmos DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## створіть вашу базу даних Cosmos DB в Azure CLI, використовуючи наступні команди\n",
    "## az login\n",
    "## az group create -n <resource-group-name> -l <location>\n",
    "## az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>\n",
    "## az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>\n",
    "\n",
    "## Після завершення перейдіть до провідника даних і створіть нову базу даних та новий контейнер\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "# Ініціалізація клієнта Cosmos\n",
    "url = os.getenv('COSMOS_DB_ENDPOINT')\n",
    "key = os.getenv('COSMOS_DB_KEY')\n",
    "client = CosmosClient(url, credential=key)\n",
    "\n",
    "# Вибір бази даних\n",
    "database_name = 'rag-cosmos-db'\n",
    "database = client.get_database_client(database_name)\n",
    "\n",
    "# Вибір контейнера\n",
    "container_name = 'data'\n",
    "container = database.get_container_client(container_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ініціалізація порожнього DataFrame\n",
    "df = pd.DataFrame(columns=['path', 'text'])\n",
    "\n",
    "\n",
    "# розбиття наших даних на фрагменти\n",
    "data_paths= [\"data/frameworks.md?WT.mc_id=academic-105485-koreyst\", \"data/own_framework.md?WT.mc_id=academic-105485-koreyst\", \"data/perceptron.md?WT.mc_id=academic-105485-koreyst\"]\n",
    "\n",
    "for path in data_paths:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "\n",
    "    # Додаємо шлях до файлу та текст до DataFrame\n",
    "    df = df.append({'path': path, 'text': file_content}, ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_length, min_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # Якщо останній фрагмент не досягнув мінімальної довжини, все одно додати його\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Припускаючи, що analyzed_df - це pandas DataFrame, а 'output_content' - це стовпець у цьому DataFrame\n",
    "splitted_df = df.copy()\n",
    "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
    "\n",
    "splitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Припускаючи, що 'chunks' - це стовпець списків у DataFrame splitted_df, ми розділимо фрагменти на різні рядки\n",
    "flattened_df = splitted_df.explode('chunks')\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перетворення нашого тексту на ембедінги\n",
    "\n",
    "Перетворення нашого тексту на ембедінги та зберігання їх у нашій базі даних у фрагментах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-ada-002-2\"):\n",
    "    # Створити ембедінги для кожного фрагмента документа\n",
    "    embeddings = openai.embeddings.create(input = text, model=model).data[0].embedding\n",
    "    return embeddings\n",
    "\n",
    "#ембедінги для першого фрагмента\n",
    "create_embeddings(flattened_df['chunks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = create_embeddings(\"cat\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# створити ембедінги для всіх фрагментів даних і зберегти їх у списку\n",
    "\n",
    "embeddings = []\n",
    "for chunk in flattened_df['chunks']:\n",
    "    embeddings.append(create_embeddings(chunk))\n",
    "\n",
    "# зберегти ембедінги в DataFrame\n",
    "flattened_df['embeddings'] = embeddings\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пошук\n",
    "\n",
    "Векторний пошук та схожість між нашим запитом і базою даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Створення індексу пошуку та переранжування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "embeddings = flattened_df['embeddings'].to_list()\n",
    "\n",
    "# Створити індекс пошуку\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\n",
    "\n",
    "# Для здійснення запиту до індексу можна використовувати метод kneighbors\n",
    "distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "# Зберегти індекси та відстані в DataFrame\n",
    "flattened_df['indices'] = indices.tolist()\n",
    "flattened_df['distances'] = distances.tolist()\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваше текстове запитання\n",
    "question = \"what is a perceptron?\"\n",
    "\n",
    "# Перетворіть запитання у вектор запиту\n",
    "query_vector = create_embeddings(question)  \n",
    "\n",
    "# Знайдіть найбільш схожі документи\n",
    "distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "index = []\n",
    "# Виведіть найбільш схожі документи\n",
    "for i in range(3):\n",
    "    index = indices[0][i]\n",
    "    for index in indices[0]:\n",
    "        print(flattened_df['chunks'].iloc[index])\n",
    "        print(flattened_df['path'].iloc[index])\n",
    "        print(flattened_df['distances'].iloc[index])\n",
    "    else:\n",
    "        print(f\"Index {index} not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поєднання всього для відповіді на запитання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"what is a perceptron?\"\n",
    "\n",
    "def chatbot(user_input):\n",
    "    # Перетворіть запитання у вектор запиту\n",
    "    query_vector = create_embeddings(user_input)\n",
    "\n",
    "    # Знайдіть найбільш схожі документи\n",
    "    distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "    # додайте документи до запиту, щоб забезпечити контекст\n",
    "    history = []\n",
    "    for index in indices[0]:\n",
    "        history.append(flattened_df['chunks'].iloc[index])\n",
    "\n",
    "    # поєднайте історію та введення користувача\n",
    "    history.append(user_input)\n",
    "\n",
    "    # створіть об'єкт повідомлення\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assiatant that helps with AI questions.\"},\n",
    "        {\"role\": \"user\", \"content\": history[-1]}\n",
    "    ]\n",
    "\n",
    "    # використайте завершення чату для генерації відповіді\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-35-turbo-1106\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "chatbot(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестування та оцінка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовий приклад того, як можна використовувати середню точність (Mean Average Precision, MAP) для оцінки відповідей вашої моделі на основі їх релевантності."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Визначте ваші тестові випадки\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What is a perceptron?\",\n",
    "        \"relevant_responses\": [\"A perceptron is a type of artificial neuron.\", \"It's a binary classifier used in machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A perceptron is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is machine learning?\",\n",
    "        \"relevant_responses\": [\"Machine learning is a method of data analysis that automates analytical model building.\", \"It's a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"],\n",
    "        \"irrelevant_responses\": [\"Machine learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is deep learning?\",\n",
    "        \"relevant_responses\": [\"Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"Deep learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a neural network?\",\n",
    "        \"relevant_responses\": [\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A neural network is a type of fruit.\", \"It's a type of car.\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Ініціалізуйте загальну середню точність\n",
    "total_average_precision = 0\n",
    "\n",
    "# Тестування програми RAG\n",
    "for test_case in test_cases:\n",
    "    query = test_case[\"query\"]\n",
    "    relevant_responses = test_case[\"relevant_responses\"]\n",
    "    irrelevant_responses = test_case[\"irrelevant_responses\"]\n",
    "\n",
    "    # Генерування відповіді за допомогою вашої програми RAG\n",
    "    response = chatbot(query) \n",
    "\n",
    "    # Створіть список усіх відповідей та список істинних бінарних міток\n",
    "    all_responses = relevant_responses + irrelevant_responses\n",
    "    true_labels = [1] * len(relevant_responses) + [0] * len(irrelevant_responses)\n",
    "\n",
    "    # Створіть список прогнозованих оцінок на основі того, чи є відповідь згенерованою відповіддю\n",
    "    predicted_scores = [1 if resp == response else 0 for resp in all_responses]\n",
    "\n",
    "    # Розрахуйте середню точність для цього запиту\n",
    "    average_precision = average_precision_score(true_labels, predicted_scores)\n",
    "\n",
    "    # Додайте середню точність до загальної середньої точності\n",
    "    total_average_precision += average_precision\n",
    "\n",
    "# Обчисліть середню точність\n",
    "mean_average_precision = total_average_precision / len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
