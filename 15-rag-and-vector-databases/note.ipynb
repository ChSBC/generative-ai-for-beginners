{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Розширення генерації на основі пошуку (RAG) та векторні бази даних"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "!pip install getenv openai==1.12.0 faiss-cpu pandas numpy"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "import openai\n",
       "import faiss"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Створення нашої бази знань\n",
       "\n",
       "Налаштування FAISS для векторного пошуку\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Перевірка встановлення FAISS\n",
       "!pip install faiss-cpu --no-cache-dir"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Ініціалізація індексу FAISS\n",
       "# Буде створено пізніше, коли знатимемо розмірність векторів\n",
       "# Типовий розмір ембедінгів ada-002 - 1536 вимірювань"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import pandas as pd\n",
       "\n",
       "# Ініціалізація порожнього DataFrame\n",
       "df = pd.DataFrame(columns=['path', 'text'])\n",
       "\n",
       "\n",
       "# розбиття наших даних на фрагменти\n",
       "data_paths= [\"data/frameworks.md?WT.mc_id=academic-105485-koreyst\", \"data/own_framework.md?WT.mc_id=academic-105485-koreyst\", \"data/perceptron.md?WT.mc_id=academic-105485-koreyst\"]\n",
       "\n",
       "for path in data_paths:\n",
       "    with open(path, 'r', encoding='utf-8') as file:\n",
       "        file_content = file.read()\n",
       "\n",
       "    # Додаємо шлях до файлу та текст до DataFrame\n",
       "    df = df.append({'path': path, 'text': file_content}, ignore_index=True)\n",
       "\n",
       "df.head()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
       "def split_text(text, max_length, min_length):\n",
       "    words = text.split()\n",
       "    chunks = []\n",
       "    current_chunk = []\n",
       "\n",
       "    for word in words:\n",
       "        current_chunk.append(word)\n",
       "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
       "            chunks.append(' '.join(current_chunk))\n",
       "            current_chunk = []\n",
       "\n",
       "    # Якщо останній фрагмент не досягнув мінімальної довжини, все одно додати його\n",
       "    if current_chunk:\n",
       "        chunks.append(' '.join(current_chunk))\n",
       "\n",
       "    return chunks\n",
       "\n",
       "# Припускаючи, що analyzed_df - це pandas DataFrame, а 'output_content' - це стовпець у цьому DataFrame\n",
       "splitted_df = df.copy()\n",
       "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
       "\n",
       "splitted_df"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Припускаючи, що 'chunks' - це стовпець списків у DataFrame splitted_df, ми розділимо фрагменти на різні рядки\n",
       "flattened_df = splitted_df.explode('chunks')\n",
       "\n",
       "flattened_df.head()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Перетворення нашого тексту на ембедінги\n",
       "\n",
       "Перетворення нашого тексту на ембедінги та зберігання їх для використання з FAISS"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
       "openai.api_type = \"azure\"\n",
       "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
       "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
       "openai.api_version = \"2023-07-01-preview\"\n",
       "\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
       "from openai import OpenAI\n",
       "client = OpenAI(api_key=os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"))"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
       "def create_embeddings(text, model=\"text-embedding-ada-002-2\"):\n",
       "    # Створити ембедінги для кожного фрагмента документа\n",
       "    embeddings = openai.embeddings.create(input = text, model=model).data[0].embedding\n",
       "    return embeddings\n",
       "\n",
       "#ембедінги для першого фрагмента\n",
       "create_embeddings(flattened_df['chunks'][0])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
       "cat = create_embeddings(\"cat\")\n",
       "cat"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
       "# створити ембедінги для всіх фрагментів даних і зберегти їх у списку\n",
       "\n",
       "embeddings = []\n",
       "for chunk in flattened_df['chunks']:\n",
       "    embeddings.append(create_embeddings(chunk))\n",
       "\n",
       "# зберегти ембедінги в DataFrame\n",
       "flattened_df['embeddings'] = embeddings\n",
       "\n",
       "flattened_df.head()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Пошук з використанням FAISS\n",
       "\n",
       "Векторний пошук та схожість між нашим запитом і базою даних з використанням FAISS"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Створення індексу FAISS та підготовка до пошуку"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "\n",
       "# Отримуємо ембедінги як масив numpy\n",
       "embeddings_list = flattened_df['embeddings'].to_list()\n",
       "embeddings_array = np.array(embeddings_list).astype('float32')\n",
       "\n",
       "# Визначаємо розмірність векторів (для ембедінгів ada-002 це 1536)\n",
       "vector_dimension = len(embeddings_list[0])\n",
       "\n",
       "# Створюємо індекс FAISS\n",
       "index = faiss.IndexFlatL2(vector_dimension)  # L2 - це евклідова відстань\n",
       "\n",
       "# Додаємо наші вектори до індексу\n",
       "index.add(embeddings_array)\n",
       "\n",
       "# Перевіряємо кількість векторів в індексі\n",
       "print(f\"Загальна кількість векторів в індексі: {index.ntotal}\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Ваше текстове запитання\n",
       "question = \"what is a perceptron?\"\n",
       "\n",
       "# Перетворіть запитання у вектор запиту\n",
       "query_vector = create_embeddings(question)  \n",
       "query_vector_array = np.array([query_vector]).astype('float32')\n",
       "\n",
       "# Знайдіть найбільш схожі документи (k=5 - скільки найближчих сусідів шукаємо)\n",
       "k = 5\n",
       "distances, indices = index.search(query_vector_array, k)\n",
       "\n",
       "# Виведіть найбільш схожі документи\n",
       "for i in range(min(3, len(indices[0]))):\n",
       "    idx = indices[0][i]\n",
       "    print(f\"Фрагмент {i+1}:\")\n",
       "    print(flattened_df['chunks'].iloc[idx])\n",
       "    print(f\"Шлях: {flattened_df['path'].iloc[idx]}\")\n",
       "    print(f\"Відстань: {distances[0][i]}\")\n",
       "    print(\"-\" * 50)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Поєднання всього для відповіді на запитання"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import openai\n",
       "\n",
       "openai.api_type = \"azure\"\n",
       "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
       "openai.api_version = \"2023-07-01-preview\"\n",
       "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
       "user_input = \"what is a perceptron?\"\n",
       "\n",
       "def chatbot(user_input):\n",
       "    # Перетворіть запитання у вектор запиту\n",
       "    query_vector = create_embeddings(user_input)\n",
       "    query_vector_array = np.array([query_vector]).astype('float32')\n",
       "    \n",
       "    # Знайдіть найбільш схожі документи з FAISS\n",
       "    k = 5  # кількість найближчих сусідів для пошуку\n",
       "    distances, indices = index.search(query_vector_array, k)\n",
       "\n",
       "    # додайте документи до запиту, щоб забезпечити контекст\n",
       "    history = []\n",
       "    for idx in indices[0]:\n",
       "        history.append(flattened_df['chunks'].iloc[idx])\n",
       "\n",
       "    # поєднайте історію та введення користувача\n",
       "    history.append(user_input)\n",
       "\n",
       "    # створіть об'єкт повідомлення\n",
       "    messages=[\n",
       "        {\"role\": \"system\", \"content\": \"You are an AI assiatant that helps with AI questions.\"},\n",
       "        {\"role\": \"user\", \"content\": history[-1]}\n",
       "    ]\n",
       "\n",
       "    # використайте завершення чату для генерації відповіді\n",
       "    response = openai.chat.completions.create(\n",
       "        model=\"gpt-35-turbo-1106\",\n",
       "        temperature=0.7,\n",
       "        max_tokens=800,\n",
       "        messages=messages\n",
       "    )\n",
       "\n",
       "    return response.choices[0].message\n",
       "\n",
       "chatbot(user_input)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Тестування та оцінка"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "Базовий приклад того, як можна використовувати середню точність (Mean Average Precision, MAP) для оцінки відповідей вашої моделі на основі їх релевантності."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
       "from sklearn.metrics import average_precision_score\n",
       "\n",
       "# Визначте ваші тестові випадки\n",
       "test_cases = [\n",
       "    {\n",
       "        \"query\": \"What is a perceptron?\",\n",
       "        \"relevant_responses\": [\"A perceptron is a type of artificial neuron.\", \"It's a binary classifier used in machine learning.\"],\n",
       "        \"irrelevant_responses\": [\"A perceptron is a type of fruit.\", \"It's a type of car.\"]\n",
       "    },\n",
       "    {\n",
       "        \"query\": \"What is machine learning?\",\n",
       "        \"relevant_responses\": [\"Machine learning is a method of data analysis that automates analytical model building.\", \"It's a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"],\n",
       "        \"irrelevant_responses\": [\"Machine learning is a type of fruit.\", \"It's a type of car.\"]\n",
       "    },\n",
       "    {\n",
       "        \"query\": \"What is deep learning?\",\n",
       "        \"relevant_responses\": [\"Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled.\", \"It's a type of machine learning.\"],\n",
       "        \"irrelevant_responses\": [\"Deep learning is a type of fruit.\", \"It's a type of car.\"]\n",
       "    },\n",
       "    {\n",
       "        \"query\": \"What is a neural network?\",\n",
       "        \"relevant_responses\": [\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.\", \"It's a type of machine learning.\"],\n",
       "        \"irrelevant_responses\": [\"A neural network is a type of fruit.\", \"It's a type of car.\"]\n",
       "    }\n",
       "]\n",
       "\n",
       "# Ініціалізуйте загальну середню точність\n",
       "total_average_precision = 0\n",
       "\n",
       "# Тестування програми RAG\n",
       "for test_case in test_cases:\n",
       "    query = test_case[\"query\"]\n",
       "    relevant_responses = test_case[\"relevant_responses\"]\n",
       "    irrelevant_responses = test_case[\"irrelevant_responses\"]\n",
       "\n",
       "    # Генерування відповіді за допомогою вашої програми RAG\n",
       "    response = chatbot(query) \n",
       "\n",
       "    # Створіть список усіх відповідей та список істинних бінарних міток\n",
       "    all_responses = relevant_responses + irrelevant_responses\n",
       "    true_labels = [1] * len(relevant_responses) + [0] * len(irrelevant_responses)\n",
       "\n",
       "    # Створіть список прогнозованих оцінок на основі того, чи є відповідь згенерованою відповіддю\n",
       "    predicted_scores = [1 if resp == response else 0 for resp in all_responses]\n",
       "\n",
       "    # Розрахуйте середню точність для цього запиту\n",
       "    average_precision = average_precision_score(true_labels, predicted_scores)\n",
       "\n",
       "    # Додайте середню точність до загальної середньої точності\n",
       "    total_average_precision += average_precision\n",
       "\n",
       "# Обчисліть середню точність\n",
       "mean_average_precision = total_average_precision / len(test_cases)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
       "mean_average_precision"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }