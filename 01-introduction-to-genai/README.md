# Вступ до Генеративного ШІ та Великих Мовних Моделей

[![Вступ до Генеративного ШІ та Великих Мовних Моделей](./images/01-lesson-banner.png)](https://aka.ms/gen-ai-lesson-1-gh)

_(Натисніть на зображення вище, щоб переглянути відео цього уроку)_

Генеративний ШІ - це штучний інтелект, здатний генерувати текст, зображення та інші типи контенту. Що робить його фантастичною технологією, так це те, що він демократизує ШІ: будь-хто може використовувати його за допомогою простого текстового запиту, речення, написаного природною мовою. Вам не потрібно вивчати мову програмування як Java чи SQL, щоб досягти чогось корисного - все, що вам потрібно, це використовувати свою мову, вказати, що ви хочете, і отримати пропозицію від моделі ШІ. Застосування та вплив цього величезні: ви можете писати або розуміти звіти, створювати програми та багато іншого, все це за лічені секунди.

У цьому курсі ми дослідимо, як наш стартап використовує генеративний ШІ для відкриття нових сценаріїв у світі освіти та як ми вирішуємо неминучі проблеми, пов'язані з соціальними наслідками його застосування та технологічними обмеженнями.

## Вступ

Цей урок охопить:

- Вступ до бізнес-сценарію: ідея та місія нашого стартапу.
- Генеративний ШІ та як ми прийшли до поточного технологічного ландшафту.
- Внутрішній принцип роботи великої мовної моделі.
- Основні можливості та практичні випадки використання Великих Мовних Моделей.

## Цілі навчання

Після завершення цього уроку ви зрозумієте:

- Що таке генеративний ШІ та як працюють Великі Мовні Моделі.
- Як ви можете використовувати великі мовні моделі для різних випадків використання, з фокусом на освітні сценарії.

## Сценарій: наш освітній стартап

Генеративний Штучний Інтелект (ШІ) представляє вершину технології ШІ, розсуваючи межі того, що колись вважалося неможливим. Моделі генеративного ШІ мають кілька можливостей та застосувань, але в цьому курсі ми дослідимо, як він революціонізує освіту через вигаданий стартап. Ми будемо називати цей стартап _нашим стартапом_. Наш стартап працює в освітній галузі з амбітною місією:

> _покращення доступності навчання в глобальному масштабі, забезпечення рівного доступу до освіти та надання персоналізованого навчального досвіду кожному учню відповідно до їхніх потреб_.

Команда нашого стартапу усвідомлює, що ми не зможемо досягти цієї мети без використання одного з найпотужніших інструментів сучасності – Великих Мовних Моделей (LLMs).

Очікується, що генеративний ШІ революціонізує спосіб навчання та викладання сьогодні: у студентів будуть віртуальні вчителі 24 години на добу, які надають величезну кількість інформації та прикладів, а вчителі зможуть використовувати інноваційні інструменти для оцінки своїх учнів та надання відгуків.

![П'ять молодих студентів дивляться на монітор - зображення від DALLE2](./images/students-by-DALLE2.png)

Для початку давайте визначимо деякі базові концепції та термінологію, які ми будемо використовувати протягом курсу.

## Як ми прийшли до Генеративного ШІ?

Незважаючи на надзвичайний _ажіотаж_, створений останнім часом анонсом моделей генеративного ШІ, ця технологія розвивається десятиліттями, перші дослідницькі зусилля датуються 60-ми роками. Зараз ми перебуваємо на етапі, коли ШІ має людські когнітивні здібності, такі як розмова, що демонструється, наприклад, [OpenAI ChatGPT](https://openai.com/chatgpt) або [Bing Chat](https://www.microsoft.com/edge/features/bing-chat), який також використовує модель GPT для веб-пошукових розмов Bing.

Повертаючись трохи назад, перші прототипи ШІ складалися з друкованих чатботів, що спиралися на базу знань, отриману від групи експертів і представлену в комп'ютері. Відповіді в базі знань запускалися ключовими словами, що з'являлися у вхідному тексті.
Однак незабаром стало зрозуміло, що такий підхід з використанням друкованих чатботів погано масштабується.

### Статистичний підхід до ШІ: Машинне навчання

Поворотний момент настав у 90-х роках із застосуванням статистичного підходу до аналізу тексту. Це призвело до розробки нових алгоритмів – відомих під назвою машинне навчання – здатних вивчати паттерни з даних без явного програмування. Цей підхід дозволяє машині імітувати розуміння людської мови: статистична модель тренується на парах текст-мітка, що дозволяє моделі класифікувати невідомий вхідний текст попередньо визначеною міткою, яка представляє намір повідомлення.

### Нейронні мережі та сучасні віртуальні асистенти

В більш недавні часи технологічна еволюція апаратного забезпечення, здатного обробляти більші обсяги даних та складніші обчислення, стимулювала дослідження в галузях ШІ, що призвело до розробки просунутих алгоритмів машинного навчання – названих нейронними мережами або алгоритмами глибокого навчання.

Нейронні мережі (і особливо Рекурентні Нейронні Мережі – RNN) значно покращили обробку природної мови, дозволяючи представляти значення тексту більш осмисленим способом, оцінюючи контекст слова в реченні.

Це технологія, яка живила віртуальних асистентів, що з'явилися в першому десятилітті нового століття, дуже вправних у інтерпретації людської мови, визначенні потреби та виконанні дії для її задоволення – наприклад, відповідаючи попередньо визначеним скриптом або використовуючи сторонній сервіс.

### Сьогодення, Генеративний ШІ

Отже, так ми прийшли до сьогоднішнього Генеративного ШІ, який можна розглядати як підмножину глибокого навчання.

![ШІ, ML, DL та Генеративний ШІ](./images/AI-diagram.png)

Після десятиліть досліджень у галузі ШІ нова архітектура моделі – названа _Трансформер_ – подолала обмеження RNN, будучи здатною отримувати набагато довші послідовності тексту як вхідні дані. Трансформери базуються на механізмі уваги, що дозволяє моделі надавати різні ваги вхідним даним, які вона отримує, 'приділяючи більше уваги' там, де зосереджена найбільш релевантна інформація, незалежно від їх порядку в текстовій послідовності.

Більшість недавніх моделей генеративного ШІ – також відомих як Великі Мовні Моделі (LLMs), оскільки вони працюють з текстовими входами та виходами – дійсно базуються на цій архітектурі. Що цікаво в цих моделях – навчених на величезній кількості нерозмічених даних з різних джерел, як-от книги, статті та веб-сайти – це те, що вони можуть бути адаптовані до широкого різноманіття завдань і генерувати граматично правильний текст з подобою творчості. Отже, вони не тільки неймовірно покращили здатність машини 'розуміти' вхідний текст, але й дали їй можливість генерувати оригінальну відповідь людською мовою.

## Як працюють великі мовні моделі?

У наступному розділі ми дослідимо різні типи моделей Генеративного ШІ, але поки що давайте подивимося, як працюють великі мовні моделі, зосередившись на моделях OpenAI GPT (Генеративний Попередньо навчений Трансформер).

- **Токенізатор, текст у числа**: Великі Мовні Моделі отримують текст як вхідні дані і генерують текст як вихідні дані. Однак, будучи статистичними моделями, вони набагато краще працюють з числами, ніж з текстовими послідовностями. Саме тому кожне вхідне значення до моделі обробляється токенізатором перед використанням основною моделлю. Токен - це фрагмент тексту, що складається зі змінної кількості символів, тому основне завдання токенізатора - розбити вхідні дані на масив токенів. Потім кожен токен зіставляється з індексом токена, який є цілочисельним кодуванням оригінального текстового фрагмента.

![Приклад токенізації](./images/tokenizer-example.png)

- **Передбачення вихідних токенів**: Отримавши n токенів як вхідні дані (з максимальним n, що варіюється від однієї моделі до іншої), модель здатна передбачити один токен як вихідні дані. Цей токен потім включається до вхідних даних наступної ітерації за pattern-ом розширюваного вікна, що забезпечує кращий користувацький досвід отримання одного (або кількох) речень як відповіді. Це пояснює, чому, якщо ви коли-небудь грали з ChatGPT, ви могли помітити, що іноді здається, ніби він зупиняється посеред речення.

- **Процес вибору, розподіл ймовірностей**: Вихідний токен вибирається моделлю відповідно до його ймовірності появи після поточної текстової послідовності. Це тому, що модель передбачає розподіл ймовірностей для всіх можливих 'наступних токенів', обчислений на основі її навчання. Однак не завжди вибирається токен з найвищою ймовірністю з отриманого розподілу. До цього вибору додається ступінь випадковості таким чином, що модель діє недетермінованим способом - ми не отримуємо точно такий же вихід для того самого входу. Цей ступінь випадковості додається для імітації процесу творчого мислення, і його можна налаштувати, використовуючи параметр моделі під назвою температура.

## Як наш стартап може використовувати Великі Мовні Моделі?

Тепер, коли ми краще розуміємо внутрішню роботу великої мовної моделі, давайте розглянемо деякі практичні приклади найпоширеніших завдань, які вони можуть виконувати досить добре, з урахуванням нашого бізнес-сценарію.
Ми сказали, що основна здатність Великої Мовної Моделі - це _генерація тексту з нуля, починаючи з текстового вводу, написаного природною мовою_.

Але який тип текстового вводу та виводу?
Вхідні дані великої мовної моделі відомі як промпт, тоді як вихідні дані відомі як завершення, термін, що відноситься до механізму моделі генерації наступного токена для завершення поточного вводу. Ми збираємося глибоко зануритися в те, що таке промпт і як спроектувати його таким чином, щоб отримати максимум від нашої моделі. Але поки що скажемо, що промпт може включати:

- **Інструкцію**, що визначає тип виводу, який ми очікуємо від моделі. Ця інструкція іноді може включати приклади або додаткові дані.

  1. Узагальнення статті, книги, відгуків про продукт тощо, а також отримання інсайтів з неструктурованих даних.
    
    ![Приклад узагальнення](./images/summarization-example.png)
  
  2. Креативне генерування ідей та написання статті, есе, завдання тощо.
      
     ![Приклад креативного письма](./images/creative-writing-example.png)

- **Запитання**, задане у формі розмови з агентом.
  
  ![Приклад розмови](./images/conversation-example.png)

- **Текст для завершення**, що неявно є проханням про допомогу в написанні.
  
  ![Приклад завершення тексту](./images/text-completion-example.png)

- **Фрагмент коду** разом із проханням пояснити та задокументувати його, або коментар із проханням згенерувати код, що виконує певне завдання.
  
  ![Приклад кодування](./images/coding-example.png)

Наведені вище приклади досить прості і не претендують на вичерпну демонстрацію можливостей Великих Мовних Моделей. Вони лише показують потенціал використання генеративного ШІ, зокрема, але не обмежуючись освітнім контекстом.

Крім того, вихід моделі генеративного ШІ не є досконалим, і іноді креативність моделі може працювати проти неї, призводячи до виходу, який є комбінацією слів, яку людина-користувач може інтерпретувати як містифікацію реальності, або він може бути образливим. Генеративний ШІ не є інтелектуальним - принаймні в більш широкому визначенні інтелекту, що включає критичне і творче мислення чи емоційний інтелект; він не є детермінованим і не є надійним, оскільки вигадки, такі як помилкові посилання, контент та твердження, можуть поєднуватися з правильною інформацією та подаватися переконливим і впевненим чином. У наступних уроках ми будемо мати справу з усіма цими обмеженнями і побачимо, що ми можемо зробити, щоб їх пом'якшити.

## Завдання

Ваше завдання - почитати більше про [генеративний ШІ](https://en.wikipedia.org/wiki/Generative_artificial_intelligence) і спробувати визначити область, де ви б додали генеративний ШІ сьогодні, де його ще немає. Яким був би вплив порівняно зі "старим способом", чи можете ви зробити щось, чого не могли раніше, чи ви просто швидші? Напишіть резюме на 300 слів про те, як би виглядав ваш омріяний ШІ-стартап, і включіть такі заголовки як "Проблема", "Як би я використовував ШІ", "Вплив" і необов'язково бізнес-план.

Якщо ви виконали це завдання, ви можете бути готові подати заявку до інкубатора Microsoft, [Microsoft for Startups Founders Hub](https://www.microsoft.com/startups) - ми пропонуємо кредити як для Azure, OpenAI, так і менторство та багато іншого, перевірте це!

## Перевірка знань

Що правильно про великі мовні моделі?

1. Ви отримуєте точно таку ж відповідь щоразу.
2. Вона робить все ідеально, чудово додає числа, створює робочий код тощо.
3. Відповідь може відрізнятися, незважаючи на використання того самого промпту. Вона також чудово підходить для створення першого варіанту чого-небудь, будь то текст чи код. Але вам потрібно покращувати результати.

В: 3, LLM є недетермінованою, відповідь варіюється, однак ви можете контролювати її варіативність через налаштування температури. Ви також не повинні очікувати, що вона робитиме все ідеально, вона тут для того, щоб виконати важку роботу за вас, що часто означає отримання хорошої першої спроби чогось, що вам потрібно поступово покращувати.

## Чудова робота! Продовжуйте подорож

Після завершення цього уроку перегляньте нашу [колекцію навчальних матеріалів з Генеративного ШІ](https://aka.ms/genai-collection), щоб продовжити підвищувати свої знання про Генеративний ШІ!

Переходьте до Уроку 2, де ми розглянемо, як [досліджувати та порівнювати різні типи LLM](../02-exploring-and-comparing-different-llms/README.md)!