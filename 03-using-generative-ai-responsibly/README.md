# Відповідальне використання Генеративного ШІ

[![Відповідальне використання Генеративного ШІ](./images/03-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Натисніть на зображення вище, щоб переглянути відео цього уроку_

Легко захопитися ШІ і особливо генеративним ШІ, але вам потрібно подумати про те, як використовувати його відповідально. Вам потрібно врахувати такі речі, як забезпечення справедливості, безпечності результатів тощо. Ця глава має на меті надати вам згаданий контекст, що потрібно враховувати і як зробити активні кроки для покращення вашого використання ШІ.

## Вступ

Цей урок охопить:

- Чому ви повинні приоритезувати Відповідальний ШІ при створенні додатків Генеративного ШІ.
- Основні принципи Відповідального ШІ та як вони пов'язані з Генеративним ШІ.
- Як втілити ці принципи Відповідального ШІ на практиці через стратегію та інструменти.

## Цілі навчання

Після завершення цього уроку ви будете знати:

- Важливість Відповідального ШІ при створенні додатків Генеративного ШІ.
- Коли думати і застосовувати основні принципи Відповідального ШІ при створенні додатків Генеративного ШІ.
- Які інструменти та стратегії доступні вам для втілення концепції Відповідального ШІ на практиці.

## Принципи Відповідального ШІ

Захоплення Генеративним ШІ ще ніколи не було таким високим. Це захоплення принесло багато нових розробників, уваги та фінансування в цю сферу. Хоча це дуже позитивно для всіх, хто хоче будувати продукти та компанії з використанням Генеративного ШІ, також важливо діяти відповідально.

Протягом цього курсу ми зосереджуємося на побудові нашого стартапу та нашого освітнього продукту на основі ШІ. Ми будемо використовувати принципи Відповідального ШІ: Справедливість, Інклюзивність, Надійність/Безпека, Захист і Приватність, Прозорість та Підзвітність. З цими принципами ми дослідимо, як вони пов'язані з нашим використанням Генеративного ШІ в наших продуктах.

## Чому варто приоритезувати Відповідальний ШІ

При створенні продукту, застосування людино-центричного підходу, тримаючи на увазі найкращі інтереси користувача, призводить до найкращих результатів.

Унікальність Генеративного ШІ полягає в його здатності створювати корисні відповіді, інформацію, керівництва та контент для користувачів. Це можна зробити без багатьох ручних кроків, що може призвести до дуже вражаючих результатів. Без належного планування та стратегій це також, на жаль, може призвести до деяких шкідливих результатів для ваших користувачів, вашого продукту та суспільства в цілому.

Давайте розглянемо деякі (але не всі) з цих потенційно шкідливих результатів:

### Галюцинації

Галюцинації - це термін, який використовується для опису ситуації, коли LLM створює контент, який або повністю безглуздий, або щось, що ми знаємо, є фактично неправильним на основі інших джерел інформації.

Наприклад, припустимо, ми створюємо функцію для нашого стартапу, яка дозволяє студентам задавати історичні питання моделі. Студент задає питання `Хто був єдиним вижившим на Титаніку?`

Модель створює таку відповідь:

![Промпт "Хто був єдиним вижившим на Титаніку"](../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp?WT.mc_id=academic-105485-koreyst)

> _(Джерело: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Це дуже впевнена і ретельна відповідь. На жаль, вона неправильна. Навіть з мінімальним дослідженням можна виявити, що було більше одного вижившого в катастрофі Титаніка. Для студента, який тільки починає досліджувати цю тему, така відповідь може бути достатньо переконливою, щоб не ставити її під сумнів і сприймати як факт. Наслідки цього можуть призвести до того, що система ШІ стане ненадійною і негативно вплине на репутацію нашого стартапу.

З кожною ітерацією будь-якої конкретної LLM ми спостерігали покращення продуктивності щодо мінімізації галюцинацій. Навіть з цим покращенням, ми як розробники додатків та користувачі все ще повинні залишатися обізнаними про ці обмеження.

### Шкідливий контент

Ми розглянули в попередньому розділі, коли LLM створює неправильні або безглузді відповіді. Інший ризик, про який нам потрібно знати, - це коли модель відповідає шкідливим контентом.

Шкідливий контент можна визначити як:

- Надання інструкцій або заохочення до самоушкодження чи шкоди певним групам.
- Ненависний або принизливий контент.
- Керівництво з планування будь-якого типу нападу чи насильницьких дій.
- Надання інструкцій щодо того, як знайти нелегальний контент або вчинити нелегальні дії.
- Відображення сексуально експліцитного контенту.

Для нашого стартапу ми хочемо переконатися, що у нас є правильні інструменти та стратегії для запобігання перегляду такого контенту студентами.

### Відсутність справедливості

Справедливість визначається як "забезпечення того, що система ШІ вільна від упереджень та дискримінації і що вона ставиться до всіх справедливо та рівно". У світі Генеративного ШІ ми хочемо забезпечити, щоб виключні світогляди маргіналізованих груп не підкріплювалися результатами моделі.

Такі типи результатів не тільки руйнівні для створення позитивного досвіду користування продуктом для наших користувачів, але вони також спричиняють подальшу суспільну шкоду. Як розробники додатків, ми завжди повинні мати на увазі широку та різноманітну базу користувачів при створенні рішень з Генеративним ШІ.

## Як відповідально використовувати Генеративний ШІ

Тепер, коли ми визначили важливість Відповідального Генеративного ШІ, давайте розглянемо 4 кроки, які ми можемо зробити для відповідальної побудови наших рішень ШІ:

![Цикл пом'якшення](./images/mitigate-cycle.png?WT.mc_id=academic-105485-koreyst)

### Вимірювання потенційної шкоди

У тестуванні програмного забезпечення ми тестуємо очікувані дії користувача в додатку. Аналогічно, тестування різноманітного набору промптів, які користувачі найімовірніше будуть використовувати, є хорошим способом виміряти потенційну шкоду.

Оскільки наш стартап створює освітній продукт, було б добре підготувати список промптів, пов'язаних з освітою. Це може бути для охоплення певного предмету, історичних фактів та промптів про студентське життя.

### Пом'якшення потенційної шкоди

Тепер час знайти способи, якими ми можемо запобігти або обмежити потенційну шкоду, спричинену моделлю та її відповідями. Ми можемо розглянути це в 4 різних шарах:

![Шари пом'якшення](./images/mitigation-layers.png?WT.mc_id=academic-105485-koreyst)

- **Модель**. Вибір правильної моделі для правильного випадку використання. Більші та складніші моделі, як GPT-4, можуть спричинити більший ризик шкідливого контенту при застосуванні до менших та більш специфічних випадків використання. Використання ваших навчальних даних для точного налаштування також зменшує ризик шкідливого контенту.

- **Система безпеки**. Система безпеки - це набір інструментів та конфігурацій на платформі, що обслуговує модель, які допомагають пом'якшити шкоду. Прикладом цього є система фільтрації контенту в сервісі Azure OpenAI. Системи також повинні виявляти атаки типу jailbreak та небажану активність, як запити від ботів.

- **Метапромпт**. Метапромпти та заземлення - це способи, якими ми можемо направляти або обмежувати модель на основі певної поведінки та інформації. Це може бути використання системних входів для визначення певних обмежень моделі. Крім того, надання результатів, які більш релевантні до сфери або домену системи.

Це також може бути використання таких технік, як Генерація з Розширенням Пошуку (RAG), щоб модель витягувала інформацію тільки з вибору довірених джерел. Пізніше в цьому курсі є урок про [створення пошукових додатків](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Користувацький досвід**. Останній шар - це де користувач безпосередньо взаємодіє з моделлю через інтерфейс нашого додатка певним чином. Таким чином ми можемо розробити UI/UX для обмеження користувача щодо типів входів, які вони можуть надсилати моделі, а також тексту чи зображень, що відображаються користувачу. При розгортанні додатка ШІ ми також повинні бути прозорими щодо того, що наш додаток Генеративного ШІ може і не може робити.

У нас є цілий урок, присвячений [Проектуванню UX для Додатків ШІ](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Оцінка моделі**. Робота з LLM може бути складною, тому що ми не завжди маємо контроль над даними, на яких модель була навчена. Незалежно від цього, ми завжди повинні оцінювати продуктивність моделі та її результати. Все ще важливо вимірювати точність моделі, подібність, обґрунтованість та релевантність результату. Це допомагає забезпечити прозорість та довіру для зацікавлених сторін та користувачів.

### Експлуатація відповідального рішення Генеративного ШІ

Побудова операційної практики навколо ваших додатків ШІ є останнім етапом. Це включає партнерство з іншими частинами нашого стартапу, такими як Юридичний відділ та Безпека, щоб забезпечити відповідність усім регуляторним політикам. Перед запуском ми також хочемо створити плани щодо доставки, обробки інцидентів та відкату, щоб запобігти зростанню будь-якої шкоди для наших користувачів.

## Інструменти

Хоча робота з розробки відповідальних рішень ШІ може здаватися великою, це робота, яка варта зусиль. Оскільки сфера Генеративного ШІ зростає, більше інструментів для допомоги розробникам ефективно інтегрувати відповідальність у їхні робочі процеси буде вдосконалюватися. Наприклад, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) може допомогти виявити шкідливий контент та зображення через API-запит.

## Перевірка знань

Про що потрібно подбати, щоб забезпечити відповідальне використання ШІ?

1. Що відповідь правильна.
1. Шкідливе використання, що ШІ не використовується для злочинних цілей.
1. Забезпечення того, що ШІ вільний від упереджень та дискримінації.

В: 2 та 3 правильні. Відповідальний ШІ допомагає вам враховувати, як пом'якшити шкідливі ефекти та упередження тощо.

## 🚀 Завдання

Прочитайте про [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) і подивіться, що ви можете прийняти для свого використання.

## Чудова робота, продовжуйте навчання

Після завершення цього уроку, перегляньте нашу [колекцію навчальних матеріалів з Генеративного ШІ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), щоб продовжити підвищувати свої знання про Генеративний ШІ!

Переходьте до Уроку 4, де ми розглянемо [Основи інженерії промптів](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!